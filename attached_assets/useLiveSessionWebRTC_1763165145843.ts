import { useEffect, useRef, useState } from 'react';
import { useAuth } from '@/hooks/useAuth';
import { useToast } from '@/hooks/use-toast';

interface Participant {
  userId: string;
  role: string;
  studentId?: string;
  isHandRaised?: boolean;
  isMuted?: boolean;
  isAudioMutedByHost?: boolean;
  reaction?: string;
}

interface Message {
  id: string;
  userId: string;
  userName: string;
  text: string;
  timestamp: string;
  isPrivate?: boolean;
}

export function useLiveSessionWebRTC(roomToken: string, onDisconnect?: () => void) {
  const { user } = useAuth();
  const { toast } = useToast();
  
  const [isAudioEnabled, setIsAudioEnabled] = useState(true);
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [isScreenSharing, setIsScreenSharing] = useState(false);
  const [participants, setParticipants] = useState<Participant[]>([]);
  const [messages, setMessages] = useState<Message[]>([]);
  const [isConnected, setIsConnected] = useState(false);
  const [remoteStreams, setRemoteStreams] = useState<Map<string, MediaStream>>(new Map());
  const [isAudioMutedByHost, setIsAudioMutedByHost] = useState(false);
  const [whiteboardCommands, setWhiteboardCommands] = useState<any[]>([]);
  
  const wsRef = useRef<WebSocket | null>(null);
  const localStreamRef = useRef<MediaStream | null>(null);
  const screenStreamRef = useRef<MediaStream | null>(null);
  const originalVideoTrackRef = useRef<MediaStreamTrack | null>(null);
  const peerConnectionRef = useRef<RTCPeerConnection | null>(null);
  const localVideoRef = useRef<HTMLVideoElement | null>(null);
  const remoteVideoRef = useRef<HTMLVideoElement | null>(null);
  const screenVideoRef = useRef<HTMLVideoElement | null>(null);

  // Initialize WebSocket connection
  useEffect(() => {
    const wsUrl = window.location.origin.replace(/^http/, 'ws') + '/ws';
    const ws = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen = () => {
      console.log('ğŸ”Œ WebSocket connected to live session');
      
      ws.send(JSON.stringify({
        type: 'auth',
        payload: { userId: user?.id, role: user?.role, studentId: user?.role === 'student' ? user?.id : undefined }
      }));
      
      ws.send(JSON.stringify({
        type: 'room:join',
        payload: { roomToken }
      }));
      
      setIsConnected(true);
    };

    ws.onmessage = (event) => {
      const message = JSON.parse(event.data);
      handleWebSocketMessage(message);
    };

    ws.onerror = (error) => {
      console.error('âŒ WebSocket error:', error);
      toast({
        variant: 'destructive',
        title: 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„',
        description: 'Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø­ØµØ©'
      });
    };

    ws.onclose = () => {
      console.log('ğŸ‘‹ WebSocket disconnected');
      setIsConnected(false);
    };

    return () => {
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({
          type: 'room:leave',
          payload: { roomToken }
        }));
      }
      ws.close();
      cleanupMedia();
    };
  }, [roomToken, user]);

  // Get user media on mount
  useEffect(() => {
    async function initMedia() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: true
        });
        
        localStreamRef.current = stream;
        
        if (localVideoRef.current) {
          localVideoRef.current.srcObject = stream;
        }
        
        console.log('ğŸ“¹ Local media acquired');
      } catch (error) {
        console.error('âŒ Error getting media:', error);
        toast({
          variant: 'destructive',
          title: 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§',
          description: 'ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†'
        });
      }
    }
    
    initMedia();
    
    return () => cleanupMedia();
  }, []);

  const handleWebSocketMessage = async (message: any) => {
    const { type, payload } = message;

    switch (type) {
      case 'room:joined':
        console.log('âœ… Joined room:', payload.roomToken);
        break;

      case 'room:participants':
        console.log('ğŸ‘¥ Participants:', payload.participants);
        setParticipants(payload.participants || []);
        
        const others = (payload.participants || []).filter((p: Participant) => p.userId !== user?.id);
        if (others.length > 0 && user?.role === 'supervisor') {
          await createOffer();
        }
        break;

      case 'webrtc:offer':
        console.log('ğŸ“¨ Received offer from:', payload.from);
        await handleOffer(payload.data);
        break;

      case 'webrtc:answer':
        console.log('ğŸ“¨ Received answer from:', payload.from);
        await handleAnswer(payload.data);
        break;

      case 'webrtc:ice-candidate':
        console.log('ğŸ§Š Received ICE candidate from:', payload.from);
        await handleIceCandidate(payload.data);
        break;

      case 'chat_message':
        setMessages(prev => [...prev, {
          id: payload.id || Date.now().toString(),
          userId: payload.senderId || payload.from || 'unknown',
          userName: payload.senderName || payload.userName || 'Ù…Ø³ØªØ®Ø¯Ù…',
          text: payload.content || payload.text || '',
          timestamp: payload.createdAt 
            ? new Date(payload.createdAt).toLocaleTimeString('ar-SA')
            : new Date().toLocaleTimeString('ar-SA')
        }]);
        break;

      case 'whiteboard:command':
        setWhiteboardCommands(prev => [...prev, {
          id: payload.id || Date.now().toString(),
          command: payload.command,
          userId: payload.userId,
          timestamp: payload.timestamp
        }]);
        break;

      case 'room:hand-raised':
      case 'room:hand-lowered':
      case 'room:reaction':
        setParticipants(prev => 
          prev.map(p => 
            p.userId === payload.userId
              ? {
                  ...p,
                  isHandRaised: type === 'room:hand-raised' ? true : type === 'room:hand-lowered' ? false : p.isHandRaised,
                  reaction: type === 'room:reaction' ? payload.reaction : p.reaction
                }
              : p
          )
        );
        break;

      case 'room:participant-muted':
        if (payload.participantId === user?.id) {
          setIsAudioMutedByHost(payload.shouldMute);
          
          if (localStreamRef.current) {
            localStreamRef.current.getAudioTracks().forEach(track => {
              track.enabled = !payload.shouldMute;
            });
            setIsAudioEnabled(!payload.shouldMute);
          }
          
          toast({
            variant: payload.shouldMute ? 'destructive' : 'default',
            title: payload.shouldMute ? 'ØªÙ… ÙƒØªÙ… ØµÙˆØªÙƒ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø´Ø±Ù' : 'Ø³Ù…Ø­ Ù„Ùƒ Ø§Ù„Ù…Ø´Ø±Ù Ø¨ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†',
            description: payload.shouldMute ? 'Ù„Ø§ ÙŠÙ…ÙƒÙ†Ùƒ ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø­ØªÙ‰ ÙŠØ³Ù…Ø­ Ø§Ù„Ù…Ø´Ø±Ù' : 'ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†'
          });
        }
        
        setParticipants(prev => 
          prev.map(p => 
            p.userId === payload.participantId
              ? { ...p, isAudioMutedByHost: payload.shouldMute }
              : p
          )
        );
        break;

      case 'room:participant-removed':
        if (payload.participantId === user?.id) {
          toast({
            variant: 'destructive',
            title: 'ØªÙ…Øª Ø¥Ø²Ø§Ù„ØªÙƒ Ù…Ù† Ø§Ù„Ø­ØµØ©',
            description: 'Ù‚Ø§Ù… Ø§Ù„Ù…Ø´Ø±Ù Ø¨Ø¥Ø²Ø§Ù„ØªÙƒ Ù…Ù† Ø§Ù„Ø­ØµØ©'
          });
          leaveRoom();
        } else {
          setParticipants(prev => prev.filter(p => p.userId !== payload.participantId));
        }
        break;

      case 'room:all-muted':
        if (user?.role === 'student') {
          setIsAudioMutedByHost(true);
          
          if (localStreamRef.current) {
            localStreamRef.current.getAudioTracks().forEach(track => {
              track.enabled = false;
            });
            setIsAudioEnabled(false);
          }
          
          toast({
            variant: 'destructive',
            title: 'ØªÙ… ÙƒØªÙ… Ø§Ù„Ø¬Ù…ÙŠØ¹',
            description: 'Ù‚Ø§Ù… Ø§Ù„Ù…Ø´Ø±Ù Ø¨ÙƒØªÙ… ØµÙˆØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ†'
          });
        }
        break;

      default:
        console.log('âš ï¸ Unknown message type:', type);
    }
  };

  const createPeerConnection = () => {
    if (peerConnectionRef.current) {
      return peerConnectionRef.current;
    }

    const configuration = {
      iceServers: [
        { urls: 'stun:stun.l.google.com:19302' },
        { urls: 'stun:stun1.l.google.com:19302' }
      ]
    };

    const pc = new RTCPeerConnection(configuration);
    peerConnectionRef.current = pc;

    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => {
        pc.addTrack(track, localStreamRef.current!);
      });
    }

    pc.onicecandidate = (event) => {
      if (event.candidate && wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'webrtc:ice-candidate',
          payload: event.candidate
        }));
      }
    };

    pc.ontrack = (event) => {
      console.log('ğŸ¥ Remote track received');
      const [remoteStream] = event.streams;
      
      if (remoteVideoRef.current) {
        remoteVideoRef.current.srcObject = remoteStream;
      }
      
      setRemoteStreams(prev => {
        const newMap = new Map(prev);
        newMap.set('remote', remoteStream);
        return newMap;
      });
    };

    pc.onconnectionstatechange = () => {
      console.log('ğŸ”„ Connection state:', pc.connectionState);
      if (pc.connectionState === 'failed') {
        toast({
          variant: 'destructive',
          title: 'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„',
          description: 'ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø´Ø§Ø±Ùƒ Ø§Ù„Ø¢Ø®Ø±'
        });
      }
    };

    return pc;
  };

  const createOffer = async () => {
    try {
      const pc = createPeerConnection();
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'webrtc:offer',
          payload: offer
        }));
        console.log('ğŸ“¤ Offer sent');
      }
    } catch (error) {
      console.error('âŒ Error creating offer:', error);
    }
  };

  const handleOffer = async (offer: RTCSessionDescriptionInit) => {
    try {
      const pc = createPeerConnection();
      await pc.setRemoteDescription(new RTCSessionDescription(offer));
      
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);

      if (wsRef.current?.readyState === WebSocket.OPEN) {
        wsRef.current.send(JSON.stringify({
          type: 'webrtc:answer',
          payload: answer
        }));
        console.log('ğŸ“¤ Answer sent');
      }
    } catch (error) {
      console.error('âŒ Error handling offer:', error);
    }
  };

  const handleAnswer = async (answer: RTCSessionDescriptionInit) => {
    try {
      const pc = peerConnectionRef.current;
      if (pc) {
        await pc.setRemoteDescription(new RTCSessionDescription(answer));
        console.log('âœ… Answer applied');
      }
    } catch (error) {
      console.error('âŒ Error handling answer:', error);
    }
  };

  const handleIceCandidate = async (candidate: RTCIceCandidateInit) => {
    try {
      const pc = peerConnectionRef.current;
      if (pc) {
        await pc.addIceCandidate(new RTCIceCandidate(candidate));
        console.log('âœ… ICE candidate added');
      }
    } catch (error) {
      console.error('âŒ Error adding ICE candidate:', error);
    }
  };

  const toggleAudio = () => {
    if (isAudioMutedByHost && !isAudioEnabled) {
      toast({
        variant: 'destructive',
        title: 'Ù„Ø§ ÙŠÙ…ÙƒÙ† ÙØªØ­ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†',
        description: 'ØªÙ… ÙƒØªÙ… ØµÙˆØªÙƒ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø´Ø±Ù'
      });
      return;
    }
    
    if (localStreamRef.current) {
      localStreamRef.current.getAudioTracks().forEach(track => {
        track.enabled = !track.enabled;
      });
      setIsAudioEnabled(prev => !prev);
    }
  };

  const toggleVideo = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getVideoTracks().forEach(track => {
        track.enabled = !track.enabled;
      });
      setIsVideoEnabled(prev => !prev);
    }
  };

  const sendMessage = (text: string) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      const senderName = user?.firstName && user?.lastName 
        ? `${user.firstName} ${user.lastName}`
        : user?.firstName || 'Ù…Ø³ØªØ®Ø¯Ù…';
      
      wsRef.current.send(JSON.stringify({
        type: 'chat_message',
        payload: {
          content: text,
          senderId: user?.id,
          senderName,
          receiverId: null,
          messageType: 'text',
          isGroupMessage: true
        }
      }));
    }
  };

  const sendWhiteboardCommand = (command: any) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'whiteboard:command',
        payload: {
          command
        }
      }));
    }
  };

  const leaveRoom = () => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'room:leave',
        payload: { roomToken }
      }));
    }
    cleanupMedia();
    onDisconnect?.();
  };

  const startScreenShare = async () => {
    try {
      const screenStream = await navigator.mediaDevices.getDisplayMedia({
        video: true,
        audio: false
      });
      
      screenStreamRef.current = screenStream;
      
      if (screenVideoRef.current) {
        screenVideoRef.current.srcObject = screenStream;
      }
      
      const pc = peerConnectionRef.current;
      if (pc && localStreamRef.current) {
        const videoTrack = screenStream.getVideoTracks()[0];
        const sender = pc.getSenders().find(s => s.track?.kind === 'video');
        
        if (sender) {
          originalVideoTrackRef.current = localStreamRef.current.getVideoTracks()[0];
          
          await sender.replaceTrack(videoTrack);
          console.log('ğŸ“º Screen sharing started - audio tracks preserved, original camera saved');
          setIsScreenSharing(true);
          
          videoTrack.onended = () => {
            stopScreenShare();
          };
          
          toast({
            title: 'Ø¨Ø¯Ø£Øª Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø´Ø§Ø´Ø©',
            description: 'ÙŠÙ…ÙƒÙ† Ù„Ù„Ø·Ù„Ø§Ø¨ Ø±Ø¤ÙŠØ© Ø´Ø§Ø´ØªÙƒ Ø§Ù„Ø¢Ù† - Ø§Ù„ØµÙˆØª Ù…Ø³ØªÙ…Ø±'
          });
        }
      }
    } catch (error) {
      console.error('âŒ Error starting screen share:', error);
      toast({
        variant: 'destructive',
        title: 'Ø®Ø·Ø£ ÙÙŠ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø´Ø§Ø´Ø©',
        description: 'Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ù…Ø´Ø§Ø±ÙƒØ© Ø´Ø§Ø´ØªÙƒ'
      });
    }
  };

  const stopScreenShare = async () => {
    try {
      if (screenStreamRef.current) {
        screenStreamRef.current.getTracks().forEach(track => track.stop());
        screenStreamRef.current = null;
      }
      
      const pc = peerConnectionRef.current;
      if (pc && originalVideoTrackRef.current) {
        const sender = pc.getSenders().find(s => s.track?.kind === 'video');
        
        if (sender) {
          await sender.replaceTrack(originalVideoTrackRef.current);
          
          if (localVideoRef.current) {
            const newStream = new MediaStream();
            newStream.addTrack(originalVideoTrackRef.current);
            if (localStreamRef.current) {
              localStreamRef.current.getAudioTracks().forEach(track => newStream.addTrack(track));
            }
            localVideoRef.current.srcObject = newStream;
          }
          
          console.log('ğŸ“º Screen sharing stopped, camera restored');
          setIsScreenSharing(false);
          originalVideoTrackRef.current = null;
          
          toast({
            title: 'ØªÙˆÙ‚ÙØª Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø´Ø§Ø´Ø©',
            description: 'Ø¹Ø¯Øª Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§'
          });
        }
      }
    } catch (error) {
      console.error('âŒ Error stopping screen share:', error);
      toast({
        variant: 'destructive',
        title: 'Ø®Ø·Ø£',
        description: 'Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§'
      });
    }
  };

  const cleanupMedia = () => {
    if (localStreamRef.current) {
      localStreamRef.current.getTracks().forEach(track => track.stop());
      localStreamRef.current = null;
    }
    
    if (screenStreamRef.current) {
      screenStreamRef.current.getTracks().forEach(track => track.stop());
      screenStreamRef.current = null;
    }
    
    if (peerConnectionRef.current) {
      peerConnectionRef.current.close();
      peerConnectionRef.current = null;
    }
  };

  const toggleHandRaise = () => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'room:toggle-hand',
        payload: { roomToken, userId: user?.id }
      }));
    }
  };

  const sendReaction = (reaction: string) => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'room:reaction',
        payload: { roomToken, userId: user?.id, reaction }
      }));
      
      setTimeout(() => {
        if (wsRef.current?.readyState === WebSocket.OPEN) {
          wsRef.current.send(JSON.stringify({
            type: 'room:reaction',
            payload: { roomToken, userId: user?.id, reaction: null }
          }));
        }
      }, 3000);
    }
  };

  const muteParticipant = (participantId: string, shouldMute: boolean) => {
    if (wsRef.current?.readyState === WebSocket.OPEN && (user?.role === 'supervisor' || user?.role === 'admin')) {
      wsRef.current.send(JSON.stringify({
        type: 'room:mute-participant',
        payload: { roomToken, participantId, shouldMute }
      }));
    }
  };

  const muteAll = () => {
    if (wsRef.current?.readyState === WebSocket.OPEN && (user?.role === 'supervisor' || user?.role === 'admin')) {
      wsRef.current.send(JSON.stringify({
        type: 'room:mute-all',
        payload: { roomToken }
      }));
      
      toast({
        title: 'ØªÙ… ÙƒØªÙ… Ø§Ù„Ø¬Ù…ÙŠØ¹',
        description: 'ØªÙ… ÙƒØªÙ… ØµÙˆØª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒÙŠÙ†'
      });
    }
  };

  const removeParticipant = (participantId: string) => {
    if (wsRef.current?.readyState === WebSocket.OPEN && (user?.role === 'supervisor' || user?.role === 'admin')) {
      wsRef.current.send(JSON.stringify({
        type: 'room:remove-participant',
        payload: { roomToken, participantId }
      }));
    }
  };

  const lockRoom = (shouldLock: boolean) => {
    if (wsRef.current?.readyState === WebSocket.OPEN && (user?.role === 'supervisor' || user?.role === 'admin')) {
      wsRef.current.send(JSON.stringify({
        type: 'room:lock',
        payload: { roomToken, isLocked: shouldLock }
      }));
      
      toast({
        title: shouldLock ? 'ØªÙ… Ù‚ÙÙ„ Ø§Ù„ØºØ±ÙØ©' : 'ØªÙ… ÙØªØ­ Ø§Ù„ØºØ±ÙØ©',
        description: shouldLock ? 'Ù„Ù† ÙŠØªÙ…ÙƒÙ† Ø£Ø­Ø¯ Ù…Ù† Ø§Ù„Ø¯Ø®ÙˆÙ„' : 'ÙŠÙ…ÙƒÙ† Ù„Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø¢Ù†'
      });
    }
  };

  return {
    isAudioEnabled,
    isVideoEnabled,
    isScreenSharing,
    participants,
    messages,
    isConnected,
    remoteStreams,
    localVideoRef,
    remoteVideoRef,
    screenVideoRef,
    toggleAudio,
    toggleVideo,
    startScreenShare,
    stopScreenShare,
    sendMessage,
    sendWhiteboardCommand,
    whiteboardCommands,
    leaveRoom,
    toggleHandRaise,
    sendReaction,
    muteParticipant,
    muteAll,
    removeParticipant,
    lockRoom,
    isAudioMutedByHost
  };
}
